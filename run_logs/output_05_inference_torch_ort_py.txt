/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torch.distributed.run.
Note that --use_env is set by default in torch.distributed.run.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
./
./resources/
./resources/data_attempts_correct_v210101b.npy
./
./resources/
./resources/data_attempts_correct_v210101b.npy
./
./resources/
./resources/data_attempts_correct_v210101b.npy
./
./resources/
./resources/data_attempts_correct_v210101b.npy
./resources/210105_0.812534_relu_e3e3.pth
./resources/data_500_last_interactions_v210101b.pkl
./resources/210105_0.812534_relu_e3e3.pth
./resources/210105_0.812534_relu_e3e3.pth
./resources/210105_0.812534_relu_e3e3.pth
./resources/data_500_last_interactions_v210101b.pkl
./resources/data_500_last_interactions_v210101b.pkl
./resources/data_500_last_interactions_v210101b.pkl
./resources/meta_v210101b.pkl
./resources/210105_0.812154_gelu_e4d4_ep30.pth
./resources/meta_v210101b.pkl
./resources/210105_0.812154_gelu_e4d4_ep30.pth
./resources/data_attempt_num_v210101b.npy
./resources/meta_v210101b.pkl
./resources/210105_0.812154_gelu_e4d4_ep30.pth
./resources/meta_v210101b.pkl
./resources/210105_0.812154_gelu_e4d4_ep30.pth
./resources/data_attempt_num_v210101b.npy
./resources/data_attempt_num_v210101b.npy
./resources/data_attempt_num_v210101b.npy
0it [00:00, ?it/s]0it [00:00, ?it/s]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
0it [00:00, ?it/s]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
0it [00:00, ?it/s]Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '1'. This changes graph semantics.
Warning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: '3'. This changes graph semantics.
0it [00:02, ?it/s, model 1=8, model 1+2=8]1it [00:02,  2.51s/it, model 1=8, model 1+2=8]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
0it [00:02, ?it/s, model 1=8, model 1+2=8]1it [00:02,  2.51s/it, model 1=8, model 1+2=8]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
1it [00:03,  2.51s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]2it [00:03,  1.47s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
1it [00:03,  2.51s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]2it [00:03,  1.45s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
2it [00:47,  1.45s/it, model 1=27, model 1+2=27, auroc (pub)=0.888889]3it [00:47, 20.85s/it, model 1=27, model 1+2=27, auroc (pub)=0.888889]0it [00:46, ?it/s, model 1=8, model 1+2=8]1it [00:46, 46.59s/it, model 1=8, model 1+2=8]0it [00:46, ?it/s, model 1=8, model 1+2=8]1it [00:46, 46.92s/it, model 1=8, model 1+2=8]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 1 more time]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
2it [00:47,  1.47s/it, model 1=27, model 1+2=27, auroc (pub)=0.847222]3it [00:47, 20.92s/it, model 1=27, model 1+2=27, auroc (pub)=0.847222]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 1 more time]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
3it [00:47, 20.85s/it, model 1=38, model 1+2=38, auroc (pub)=0.894737]4it [00:47, 12.80s/it, model 1=38, model 1+2=38, auroc (pub)=0.894737]3it [00:47, 20.92s/it, model 1=38, model 1+2=38, auroc (pub)=0.842105]4it [00:47, 12.83s/it, model 1=38, model 1+2=38, auroc (pub)=0.842105]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 2 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 2 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
4it [00:48, 12.83s/it, model 1=57, model 1+2=57, auroc (pub)=0.764615]5it [00:48,  8.31s/it, model 1=57, model 1+2=57, auroc (pub)=0.764615]4it [00:47, 12.80s/it, model 1=57, model 1+2=57, auroc (pub)=0.887692]5it [00:47,  8.29s/it, model 1=57, model 1+2=57, auroc (pub)=0.887692]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 3 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 3 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
5it [00:48,  8.31s/it, model 1=76, model 1+2=76, auroc (pub)=0.769595]6it [00:48,  5.59s/it, model 1=76, model 1+2=76, auroc (pub)=0.769595]5it [00:48,  8.29s/it, model 1=76, model 1+2=76, auroc (pub)=0.843919]6it [00:48,  5.58s/it, model 1=76, model 1+2=76, auroc (pub)=0.843919]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
1it [00:47, 46.59s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]2it [00:47, 19.81s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 4 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 4 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
1it [00:47, 46.92s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]2it [00:47, 19.95s/it, model 1=18, model 1+2=18, auroc (pub)=0.866667]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
2it [00:48, 19.81s/it, model 1=27, model 1+2=27, auroc (pub)=0.944444]3it [00:48, 11.01s/it, model 1=27, model 1+2=27, auroc (pub)=0.944444]2it [00:48, 19.95s/it, model 1=27, model 1+2=27, auroc (pub)=0.930556]3it [00:48, 11.08s/it, model 1=27, model 1+2=27, auroc (pub)=0.930556]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 1 more time]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 1 more time]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
6it [00:48,  5.59s/it, model 1=96, model 1+2=96, auroc (pub)=0.803008]7it [00:48,  3.96s/it, model 1=96, model 1+2=96, auroc (pub)=0.803008]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 5 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
6it [00:48,  5.58s/it, model 1=96, model 1+2=96, auroc (pub)=0.832355]7it [00:48,  3.96s/it, model 1=96, model 1+2=96, auroc (pub)=0.832355]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 5 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
3it [00:48, 11.01s/it, model 1=38, model 1+2=38, auroc (pub)=0.953947]4it [00:48,  6.89s/it, model 1=38, model 1+2=38, auroc (pub)=0.953947]3it [00:49, 11.08s/it, model 1=38, model 1+2=38, auroc (pub)=0.940789]4it [00:49,  6.93s/it, model 1=38, model 1+2=38, auroc (pub)=0.940789]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 2 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 2 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
7it [00:49,  3.96s/it, model 1=120, model 1+2=120, auroc (pub)=0.762258]8it [00:49,  2.92s/it, model 1=120, model 1+2=120, auroc (pub)=0.762258]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 6 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
7it [00:49,  3.96s/it, model 1=120, model 1+2=120, auroc (pub)=0.775304]8it [00:49,  2.92s/it, model 1=120, model 1+2=120, auroc (pub)=0.775304]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 6 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
4it [00:49,  6.93s/it, model 1=57, model 1+2=57, auroc (pub)=0.935385]5it [00:49,  4.66s/it, model 1=57, model 1+2=57, auroc (pub)=0.935385]4it [00:49,  6.89s/it, model 1=57, model 1+2=57, auroc (pub)=0.947692]5it [00:49,  4.63s/it, model 1=57, model 1+2=57, auroc (pub)=0.947692]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 3 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 3 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
8it [00:50,  2.92s/it, model 1=140, model 1+2=140, auroc (pub)=0.730639]9it [00:50,  2.17s/it, model 1=140, model 1+2=140, auroc (pub)=0.730639]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 7 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
8it [00:50,  2.92s/it, model 1=140, model 1+2=140, auroc (pub)=0.755984]9it [00:50,  2.16s/it, model 1=140, model 1+2=140, auroc (pub)=0.755984]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 7 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
5it [00:50,  4.66s/it, model 1=76, model 1+2=76, auroc (pub)=0.921622]6it [00:50,  3.29s/it, model 1=76, model 1+2=76, auroc (pub)=0.921622]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
5it [00:50,  4.63s/it, model 1=76, model 1+2=76, auroc (pub)=0.935135]6it [00:50,  3.27s/it, model 1=76, model 1+2=76, auroc (pub)=0.935135]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 4 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
9it [00:50,  2.17s/it, model 1=160, model 1+2=160, auroc (pub)=0.743043]10it [00:50,  1.67s/it, model 1=160, model 1+2=160, auroc (pub)=0.743043]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 4 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
9it [00:50,  2.16s/it, model 1=160, model 1+2=160, auroc (pub)=0.762626]10it [00:50,  1.66s/it, model 1=160, model 1+2=160, auroc (pub)=0.762626]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 8 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 8 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
6it [00:51,  3.29s/it, model 1=96, model 1+2=96, auroc (pub)=0.938371]7it [00:51,  2.43s/it, model 1=96, model 1+2=96, auroc (pub)=0.938371]6it [00:50,  3.27s/it, model 1=96, model 1+2=96, auroc (pub)=0.948643]7it [00:50,  2.42s/it, model 1=96, model 1+2=96, auroc (pub)=0.948643]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
10it [00:51,  1.67s/it, model 1=181, model 1+2=181, auroc (pub)=0.753049]11it [00:51,  1.36s/it, model 1=181, model 1+2=181, auroc (pub)=0.753049]10it [00:51,  1.66s/it, model 1=181, model 1+2=181, auroc (pub)=0.770560]11it [00:51,  1.36s/it, model 1=181, model 1+2=181, auroc (pub)=0.770560]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 5 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 5 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 9 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 9 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
7it [00:51,  2.43s/it, model 1=120, model 1+2=120, auroc (pub)=0.884840]8it [00:51,  1.89s/it, model 1=120, model 1+2=120, auroc (pub)=0.884840]11it [00:52,  1.36s/it, model 1=201, model 1+2=201, auroc (pub)=0.765327]12it [00:52,  1.17s/it, model 1=201, model 1+2=201, auroc (pub)=0.765327]11it [00:51,  1.36s/it, model 1=201, model 1+2=201, auroc (pub)=0.785357]12it [00:51,  1.17s/it, model 1=201, model 1+2=201, auroc (pub)=0.785357]7it [00:51,  2.42s/it, model 1=120, model 1+2=120, auroc (pub)=0.900585]8it [00:51,  1.88s/it, model 1=120, model 1+2=120, auroc (pub)=0.900585]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 6 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 10 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 10 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 6 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
8it [00:52,  1.88s/it, model 1=140, model 1+2=140, auroc (pub)=0.908758]9it [00:52,  1.52s/it, model 1=140, model 1+2=140, auroc (pub)=0.908758]12it [00:52,  1.17s/it, model 1=219, model 1+2=219, auroc (pub)=0.781976]13it [00:52,  1.04s/it, model 1=219, model 1+2=219, auroc (pub)=0.781976]12it [00:52,  1.17s/it, model 1=219, model 1+2=219, auroc (pub)=0.794786]8it [00:52,  1.89s/it, model 1=140, model 1+2=140, auroc (pub)=0.892706]13it [00:52,  1.03s/it, model 1=219, model 1+2=219, auroc (pub)=0.794786]9it [00:52,  1.53s/it, model 1=140, model 1+2=140, auroc (pub)=0.892706]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 7 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 7 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 11 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 11 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
9it [00:53,  1.53s/it, model 1=160, model 1+2=160, auroc (pub)=0.901464]10it [00:53,  1.31s/it, model 1=160, model 1+2=160, auroc (pub)=0.901464]9it [00:52,  1.52s/it, model 1=160, model 1+2=160, auroc (pub)=0.913832]10it [00:52,  1.30s/it, model 1=160, model 1+2=160, auroc (pub)=0.913832]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 8 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 8 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
13it [00:53,  1.04s/it, model 1=242, model 1+2=242, auroc (pub)=0.792647]14it [00:53,  1.03it/s, model 1=242, model 1+2=242, auroc (pub)=0.792647]13it [00:53,  1.03s/it, model 1=242, model 1+2=242, auroc (pub)=0.804916]14it [00:53,  1.03it/s, model 1=242, model 1+2=242, auroc (pub)=0.804916]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 12 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 12 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
10it [00:54,  1.31s/it, model 1=181, model 1+2=181, auroc (pub)=0.910100]11it [00:54,  1.16s/it, model 1=181, model 1+2=181, auroc (pub)=0.910100]10it [00:53,  1.30s/it, model 1=181, model 1+2=181, auroc (pub)=0.922452]11it [00:53,  1.16s/it, model 1=181, model 1+2=181, auroc (pub)=0.922452]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 9 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 9 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
14it [00:54,  1.03it/s, model 1=274, model 1+2=274, auroc (pub)=0.787504]15it [00:54,  1.04it/s, model 1=274, model 1+2=274, auroc (pub)=0.787504]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
14it [00:54,  1.03it/s, model 1=274, model 1+2=274, auroc (pub)=0.795950]15it [00:54,  1.04it/s, model 1=274, model 1+2=274, auroc (pub)=0.795950]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 13 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 13 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
11it [00:55,  1.16s/it, model 1=201, model 1+2=201, auroc (pub)=0.921959]12it [00:55,  1.09s/it, model 1=201, model 1+2=201, auroc (pub)=0.921959]11it [00:54,  1.16s/it, model 1=201, model 1+2=201, auroc (pub)=0.931607]12it [00:54,  1.09s/it, model 1=201, model 1+2=201, auroc (pub)=0.931607]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 10 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 10 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
15it [00:55,  1.04it/s, model 1=310, model 1+2=310, auroc (pub)=0.803490]16it [00:55,  1.02s/it, model 1=310, model 1+2=310, auroc (pub)=0.803490]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 14 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
15it [00:55,  1.04it/s, model 1=310, model 1+2=310, auroc (pub)=0.801163]16it [00:55,  1.03s/it, model 1=310, model 1+2=310, auroc (pub)=0.801163]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 14 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
12it [00:55,  1.09s/it, model 1=219, model 1+2=219, auroc (pub)=0.925521]13it [00:55,  1.00s/it, model 1=219, model 1+2=219, auroc (pub)=0.925521]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 11 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
12it [00:55,  1.09s/it, model 1=219, model 1+2=219, auroc (pub)=0.929891]13it [00:55,  1.01s/it, model 1=219, model 1+2=219, auroc (pub)=0.929891]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 11 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
16it [00:56,  1.02s/it, model 1=337, model 1+2=337, auroc (pub)=0.816492]17it [00:56,  1.04s/it, model 1=337, model 1+2=337, auroc (pub)=0.816492]16it [00:56,  1.03s/it, model 1=337, model 1+2=337, auroc (pub)=0.809937]17it [00:56,  1.04s/it, model 1=337, model 1+2=337, auroc (pub)=0.809937]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 15 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 15 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
13it [00:56,  1.00s/it, model 1=242, model 1+2=242, auroc (pub)=0.933782]14it [00:56,  1.10it/s, model 1=242, model 1+2=242, auroc (pub)=0.933782]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 12 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
13it [00:56,  1.01s/it, model 1=242, model 1+2=242, auroc (pub)=0.936471]14it [00:56,  1.10it/s, model 1=242, model 1+2=242, auroc (pub)=0.936471]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 12 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
17it [00:57,  1.04s/it, model 1=370, model 1+2=370, auroc (pub)=0.810686]18it [00:57,  1.05s/it, model 1=370, model 1+2=370, auroc (pub)=0.810686]17it [00:57,  1.04s/it, model 1=370, model 1+2=370, auroc (pub)=0.799947]18it [00:57,  1.04s/it, model 1=370, model 1+2=370, auroc (pub)=0.799947]14it [00:57,  1.10it/s, model 1=274, model 1+2=274, auroc (pub)=0.929595]15it [00:57,  1.06it/s, model 1=274, model 1+2=274, auroc (pub)=0.929595]14it [00:57,  1.10it/s, model 1=274, model 1+2=274, auroc (pub)=0.928972]15it [00:57,  1.07it/s, model 1=274, model 1+2=274, auroc (pub)=0.928972]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 16 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 16 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 13 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 13 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
18it [00:59,  1.05s/it, model 1=403, model 1+2=403, auroc (pub)=0.798171]19it [00:59,  1.06s/it, model 1=403, model 1+2=403, auroc (pub)=0.798171]18it [00:58,  1.04s/it, model 1=403, model 1+2=403, auroc (pub)=0.795296]19it [00:58,  1.06s/it, model 1=403, model 1+2=403, auroc (pub)=0.795296]15it [00:58,  1.07it/s, model 1=310, model 1+2=310, auroc (pub)=0.931331]16it [00:58,  1.02it/s, model 1=310, model 1+2=310, auroc (pub)=0.931331]15it [00:58,  1.06it/s, model 1=310, model 1+2=310, auroc (pub)=0.934037]16it [00:58,  1.01it/s, model 1=310, model 1+2=310, auroc (pub)=0.934037]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 17 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 17 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 14 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 14 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
16it [00:59,  1.01it/s, model 1=337, model 1+2=337, auroc (pub)=0.938445]17it [00:59,  1.02s/it, model 1=337, model 1+2=337, auroc (pub)=0.938445]16it [00:59,  1.02it/s, model 1=337, model 1+2=337, auroc (pub)=0.936639]17it [00:59,  1.02s/it, model 1=337, model 1+2=337, auroc (pub)=0.936639]19it [01:00,  1.06s/it, model 1=430, model 1+2=430, auroc (pub)=0.790797]19it [01:00,  1.06s/it, model 1=430, model 1+2=430, auroc (pub)=0.795158]20it [01:00,  1.08s/it, model 1=430, model 1+2=430, auroc (pub)=0.790797]20it [01:00,  1.08s/it, model 1=430, model 1+2=430, auroc (pub)=0.795158]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 15 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 15 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 18 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 18 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
20it [01:01,  1.08s/it, model 1=459, model 1+2=459, auroc (pub)=0.790887]21it [01:01,  1.09s/it, model 1=459, model 1+2=459, auroc (pub)=0.790887]20it [01:01,  1.08s/it, model 1=459, model 1+2=459, auroc (pub)=0.789250]21it [01:01,  1.09s/it, model 1=459, model 1+2=459, auroc (pub)=0.789250]17it [01:00,  1.02s/it, model 1=370, model 1+2=370, auroc (pub)=0.932717]18it [01:00,  1.06s/it, model 1=370, model 1+2=370, auroc (pub)=0.932717]17it [01:00,  1.02s/it, model 1=370, model 1+2=370, auroc (pub)=0.932788]18it [01:00,  1.06s/it, model 1=370, model 1+2=370, auroc (pub)=0.932788]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 19 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 16 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 16 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 19 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
18it [01:02,  1.06s/it, model 1=403, model 1+2=403, auroc (pub)=0.928648]19it [01:02,  1.09s/it, model 1=403, model 1+2=403, auroc (pub)=0.928648]21it [01:02,  1.09s/it, model 1=489, model 1+2=489, auroc (pub)=0.786425]22it [01:02,  1.12s/it, model 1=489, model 1+2=489, auroc (pub)=0.786425]21it [01:02,  1.09s/it, model 1=489, model 1+2=489, auroc (pub)=0.782063]18it [01:01,  1.06s/it, model 1=403, model 1+2=403, auroc (pub)=0.931345]19it [01:01,  1.09s/it, model 1=403, model 1+2=403, auroc (pub)=0.931345]22it [01:02,  1.12s/it, model 1=489, model 1+2=489, auroc (pub)=0.782063]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 17 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 20 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 17 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 20 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
19it [01:03,  1.09s/it, model 1=430, model 1+2=430, auroc (pub)=0.927909]20it [01:03,  1.16s/it, model 1=430, model 1+2=430, auroc (pub)=0.927909]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
22it [01:03,  1.12s/it, model 1=520, model 1+2=520, auroc (pub)=0.786210]23it [01:03,  1.18s/it, model 1=520, model 1+2=520, auroc (pub)=0.786210]19it [01:03,  1.09s/it, model 1=430, model 1+2=430, auroc (pub)=0.930858]20it [01:03,  1.16s/it, model 1=430, model 1+2=430, auroc (pub)=0.930858]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 18 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
22it [01:03,  1.12s/it, model 1=520, model 1+2=520, auroc (pub)=0.785643]23it [01:03,  1.18s/it, model 1=520, model 1+2=520, auroc (pub)=0.785643]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 21 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 18 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 21 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
20it [01:04,  1.16s/it, model 1=459, model 1+2=459, auroc (pub)=0.927718]21it [01:04,  1.18s/it, model 1=459, model 1+2=459, auroc (pub)=0.927718]20it [01:04,  1.16s/it, model 1=459, model 1+2=459, auroc (pub)=0.931280]21it [01:04,  1.18s/it, model 1=459, model 1+2=459, auroc (pub)=0.931280]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 19 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
23it [01:05,  1.18s/it, model 1=554, model 1+2=554, auroc (pub)=0.789375]24it [01:05,  1.20s/it, model 1=554, model 1+2=554, auroc (pub)=0.789375]23it [01:04,  1.18s/it, model 1=554, model 1+2=554, auroc (pub)=0.786525]24it [01:04,  1.20s/it, model 1=554, model 1+2=554, auroc (pub)=0.786525]/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 19 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 22 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 22 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
21it [01:05,  1.18s/it, model 1=489, model 1+2=489, auroc (pub)=0.923216]22it [01:05,  1.23s/it, model 1=489, model 1+2=489, auroc (pub)=0.923216]21it [01:05,  1.18s/it, model 1=489, model 1+2=489, auroc (pub)=0.927559]22it [01:05,  1.23s/it, model 1=489, model 1+2=489, auroc (pub)=0.927559]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 20 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 20 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
24it [01:06,  1.20s/it, model 1=592, model 1+2=592, auroc (pub)=0.786796]25it [01:06,  1.24s/it, model 1=592, model 1+2=592, auroc (pub)=0.786796]24it [01:06,  1.20s/it, model 1=592, model 1+2=592, auroc (pub)=0.788040]25it [01:06,  1.24s/it, model 1=592, model 1+2=592, auroc (pub)=0.788040]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 23 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 23 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
22it [01:07,  1.23s/it, model 1=520, model 1+2=520, auroc (pub)=0.930992]23it [01:07,  1.29s/it, model 1=520, model 1+2=520, auroc (pub)=0.930992]22it [01:07,  1.23s/it, model 1=520, model 1+2=520, auroc (pub)=0.927296]23it [01:07,  1.29s/it, model 1=520, model 1+2=520, auroc (pub)=0.927296]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 21 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 21 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
25it [01:07,  1.24s/it, model 1=639, model 1+2=639, auroc (pub)=0.785547]26it [01:07,  1.34s/it, model 1=639, model 1+2=639, auroc (pub)=0.785547]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 24 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
25it [01:07,  1.24s/it, model 1=639, model 1+2=639, auroc (pub)=0.791954]26it [01:07,  1.36s/it, model 1=639, model 1+2=639, auroc (pub)=0.791954]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 24 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
23it [01:08,  1.29s/it, model 1=554, model 1+2=554, auroc (pub)=0.932986]24it [01:08,  1.34s/it, model 1=554, model 1+2=554, auroc (pub)=0.932986]23it [01:08,  1.29s/it, model 1=554, model 1+2=554, auroc (pub)=0.930274]24it [01:08,  1.34s/it, model 1=554, model 1+2=554, auroc (pub)=0.930274]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 22 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 22 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
26it [01:09,  1.34s/it, model 1=688, model 1+2=688, auroc (pub)=0.778108]27it [01:09,  1.44s/it, model 1=688, model 1+2=688, auroc (pub)=0.778108]26it [01:09,  1.36s/it, model 1=688, model 1+2=688, auroc (pub)=0.776391]27it [01:09,  1.44s/it, model 1=688, model 1+2=688, auroc (pub)=0.776391]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 25 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 25 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
24it [01:10,  1.34s/it, model 1=592, model 1+2=592, auroc (pub)=0.933502]25it [01:10,  1.40s/it, model 1=592, model 1+2=592, auroc (pub)=0.933502]24it [01:10,  1.34s/it, model 1=592, model 1+2=592, auroc (pub)=0.931056]25it [01:10,  1.40s/it, model 1=592, model 1+2=592, auroc (pub)=0.931056]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 23 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 23 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
27it [01:10,  1.44s/it, model 1=731, model 1+2=731, auroc (pub)=0.774465]28it [01:10,  1.37s/it, model 1=731, model 1+2=731, auroc (pub)=0.774465]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 26 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
27it [01:11,  1.44s/it, model 1=731, model 1+2=731, auroc (pub)=0.779375]28it [01:11,  1.51s/it, model 1=731, model 1+2=731, auroc (pub)=0.779375]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 26 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
25it [01:12,  1.40s/it, model 1=639, model 1+2=639, auroc (pub)=0.926683]26it [01:12,  1.48s/it, model 1=639, model 1+2=639, auroc (pub)=0.926683]25it [01:11,  1.40s/it, model 1=639, model 1+2=639, auroc (pub)=0.930986]26it [01:11,  1.49s/it, model 1=639, model 1+2=639, auroc (pub)=0.930986]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 24 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
28it [01:12,  1.37s/it, model 1=780, model 1+2=780, auroc (pub)=0.768119]29it [01:12,  1.45s/it, model 1=780, model 1+2=780, auroc (pub)=0.768119]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 24 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 27 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
28it [01:12,  1.51s/it, model 1=780, model 1+2=780, auroc (pub)=0.780213]29it [01:12,  1.43s/it, model 1=780, model 1+2=780, auroc (pub)=0.780213]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 27 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
26it [01:13,  1.48s/it, model 1=688, model 1+2=688, auroc (pub)=0.924093]26it [01:13,  1.49s/it, model 1=688, model 1+2=688, auroc (pub)=0.928616]27it [01:13,  1.57s/it, model 1=688, model 1+2=688, auroc (pub)=0.924093]27it [01:13,  1.57s/it, model 1=688, model 1+2=688, auroc (pub)=0.928616]29it [01:14,  1.45s/it, model 1=831, model 1+2=831, auroc (pub)=0.767553]30it [01:14,  1.54s/it, model 1=831, model 1+2=831, auroc (pub)=0.767553]29it [01:14,  1.43s/it, model 1=831, model 1+2=831, auroc (pub)=0.775983]30it [01:14,  1.51s/it, model 1=831, model 1+2=831, auroc (pub)=0.775983]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 25 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 25 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 28 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 28 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
27it [01:15,  1.57s/it, model 1=731, model 1+2=731, auroc (pub)=0.929013]28it [01:15,  1.62s/it, model 1=731, model 1+2=731, auroc (pub)=0.929013]27it [01:15,  1.57s/it, model 1=731, model 1+2=731, auroc (pub)=0.926778]28it [01:15,  1.62s/it, model 1=731, model 1+2=731, auroc (pub)=0.926778]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 26 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 26 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
30it [01:15,  1.51s/it, model 1=888, model 1+2=888, auroc (pub)=0.772424]31it [01:15,  1.62s/it, model 1=888, model 1+2=888, auroc (pub)=0.772424]30it [01:16,  1.54s/it, model 1=888, model 1+2=888, auroc (pub)=0.769883]31it [01:16,  1.64s/it, model 1=888, model 1+2=888, auroc (pub)=0.769883]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 29 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 29 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
31it [01:17,  2.49s/it, model 1=888, model 1+2=888, auroc (pub)=0.769883]
Traceback (most recent call last):
  File "05_inference_torch_ort.py", line 838, in <module>
    preds2 = model2(x_mask, x_cat, x_cont, x_tags, x_tagw)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/ortmodule.py", line 81, in _forward
    return self._torch_module.forward(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_torch_module_ort.py", line 32, in _forward
    return self._execution_manager(self.is_training()).forward(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 66, in forward
    return self._fallback_manager.fallback(self._original_module, self._debug_options.logging.log_level, *inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 218, in fallback
    return model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "05_inference_torch_ort.py", line 273, in forward
    o = self.trafo(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/transformer.py", line 138, in forward
    output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/transformer.py", line 245, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/transformer.py", line 408, in forward
    tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1031, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/functional.py", line 5082, in multi_head_attention_forward
    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/functional.py", line 4828, in _scaled_dot_product_attention
    attn = softmax(attn, dim=-1)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/nn/functional.py", line 1679, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 15.78 GiB total capacity; 1.51 GiB already allocated; 54.50 MiB free; 1.91 GiB reserved in total by PyTorch)
28it [01:16,  1.62s/it, model 1=780, model 1+2=780, auroc (pub)=0.928104]29it [01:16,  1.66s/it, model 1=780, model 1+2=780, auroc (pub)=0.928104]28it [01:17,  1.62s/it, model 1=780, model 1+2=780, auroc (pub)=0.924466]29it [01:17,  1.66s/it, model 1=780, model 1+2=780, auroc (pub)=0.924466]31it [01:17,  1.62s/it, model 1=945, model 1+2=945, auroc (pub)=0.768498]32it [01:17,  1.62s/it, model 1=945, model 1+2=945, auroc (pub)=0.768498]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 27 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 27 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 30 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
29it [01:18,  1.66s/it, model 1=831, model 1+2=831, auroc (pub)=0.921004]30it [01:18,  1.58s/it, model 1=831, model 1+2=831, auroc (pub)=0.921004]29it [01:18,  1.66s/it, model 1=831, model 1+2=831, auroc (pub)=0.925402]30it [01:18,  1.58s/it, model 1=831, model 1+2=831, auroc (pub)=0.925402]32it [01:18,  1.62s/it, model 1=1005, model 1+2=1005, eta=54.556/8.716, auroc (pub)=0.766968]33it [01:18,  1.55s/it, model 1=1005, model 1+2=1005, eta=54.556/8.716, auroc (pub)=0.766968]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 28 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 28 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 31 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
33it [01:20,  1.55s/it, model 1=1066, model 1+2=1005, eta=52.139/8.716, auroc (pub)=0.774856]34it [01:20,  1.41s/it, model 1=1066, model 1+2=1005, eta=52.139/8.716, auroc (pub)=0.774856]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 32 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
30it [01:19,  1.58s/it, model 1=888, model 1+2=888, auroc (pub)=0.927583]31it [01:19,  1.49s/it, model 1=888, model 1+2=888, auroc (pub)=0.927583]30it [01:19,  1.58s/it, model 1=888, model 1+2=888, auroc (pub)=0.922597]31it [01:19,  1.49s/it, model 1=888, model 1+2=888, auroc (pub)=0.922597]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 29 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 29 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
34it [01:20,  1.41s/it, model 1=1122, model 1+2=1005, eta=50.129/8.716, auroc (pub)=0.779014]35it [01:20,  1.27s/it, model 1=1122, model 1+2=1005, eta=50.129/8.716, auroc (pub)=0.779014]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 33 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
35it [01:21,  1.27s/it, model 1=1177, model 1+2=1005, eta=48.041/8.716, auroc (pub)=0.781197]36it [01:21,  1.02s/it, model 1=1177, model 1+2=1005, eta=48.041/8.716, auroc (pub)=0.781197]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 34 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
31it [01:21,  1.49s/it, model 1=945, model 1+2=945, auroc (pub)=0.922948]32it [01:21,  1.41s/it, model 1=945, model 1+2=945, auroc (pub)=0.922948]31it [01:20,  1.49s/it, model 1=945, model 1+2=945, auroc (pub)=0.926536]32it [01:20,  1.41s/it, model 1=945, model 1+2=945, auroc (pub)=0.926536]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 30 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 30 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
36it [01:22,  1.02s/it, model 1=1233, model 1+2=1005, eta=46.479/8.716, auroc (pub)=0.781293]37it [01:22,  1.04s/it, model 1=1233, model 1+2=1005, eta=46.479/8.716, auroc (pub)=0.781293]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 35 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
32it [01:22,  1.41s/it, model 1=1005, model 1+2=1005, eta=57.048/8.716, auroc (pub)=0.916511]33it [01:22,  1.39s/it, model 1=1005, model 1+2=1005, eta=57.048/8.716, auroc (pub)=0.916511]32it [01:22,  1.41s/it, model 1=1005, model 1+2=1005, eta=56.817/8.716, auroc (pub)=0.920595]33it [01:22,  1.39s/it, model 1=1005, model 1+2=1005, eta=56.817/8.716, auroc (pub)=0.920595]37it [01:22,  1.04s/it, model 1=1290, model 1+2=1005, eta=44.577/8.716, auroc (pub)=0.780730]38it [01:22,  1.23it/s, model 1=1290, model 1+2=1005, eta=44.577/8.716, auroc (pub)=0.780730]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 31 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 36 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 31 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
38it [01:23,  1.23it/s, model 1=1342, model 1+2=1005, eta=43.176/8.716, auroc (pub)=0.775306]39it [01:23,  1.32it/s, model 1=1342, model 1+2=1005, eta=43.176/8.716, auroc (pub)=0.775306]33it [01:23,  1.39s/it, model 1=1066, model 1+2=1005, eta=54.200/8.716, auroc (pub)=0.917176]34it [01:23,  1.16s/it, model 1=1066, model 1+2=1005, eta=54.200/8.716, auroc (pub)=0.917176]33it [01:22,  1.39s/it, model 1=1066, model 1+2=1005, eta=53.981/8.716, auroc (pub)=0.919950]34it [01:22,  1.16s/it, model 1=1066, model 1+2=1005, eta=53.981/8.716, auroc (pub)=0.919950]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 37 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 32 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 32 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
34it [01:23,  1.16s/it, model 1=1122, model 1+2=1005, eta=51.681/8.716, auroc (pub)=0.917480]39it [01:24,  1.32it/s, model 1=1401, model 1+2=1005, eta=41.676/8.716, auroc (pub)=0.776228]35it [01:23,  1.01s/it, model 1=1122, model 1+2=1005, eta=51.681/8.716, auroc (pub)=0.917480]40it [01:24,  1.38it/s, model 1=1401, model 1+2=1005, eta=41.676/8.716, auroc (pub)=0.776228]34it [01:23,  1.16s/it, model 1=1122, model 1+2=1005, eta=51.891/8.716, auroc (pub)=0.915459]35it [01:23,  1.01s/it, model 1=1122, model 1+2=1005, eta=51.891/8.716, auroc (pub)=0.915459]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 33 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 38 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 33 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
35it [01:24,  1.01s/it, model 1=1177, model 1+2=1005, eta=49.654/8.716, auroc (pub)=0.914746]36it [01:24,  1.11it/s, model 1=1177, model 1+2=1005, eta=49.654/8.716, auroc (pub)=0.914746]35it [01:24,  1.01s/it, model 1=1177, model 1+2=1005, eta=49.854/8.716, auroc (pub)=0.912118]36it [01:24,  1.11it/s, model 1=1177, model 1+2=1005, eta=49.854/8.716, auroc (pub)=0.912118]40it [01:24,  1.38it/s, model 1=1463, model 1+2=1005, eta=40.224/8.716, auroc (pub)=0.779588]41it [01:24,  1.42it/s, model 1=1463, model 1+2=1005, eta=40.224/8.716, auroc (pub)=0.779588]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 34 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 34 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 39 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
36it [01:25,  1.11it/s, model 1=1233, model 1+2=1005, eta=47.952/8.716, auroc (pub)=0.909210]37it [01:25,  1.21it/s, model 1=1233, model 1+2=1005, eta=47.952/8.716, auroc (pub)=0.909210]36it [01:24,  1.11it/s, model 1=1233, model 1+2=1005, eta=47.763/8.716, auroc (pub)=0.912798]37it [01:24,  1.21it/s, model 1=1233, model 1+2=1005, eta=47.763/8.716, auroc (pub)=0.912798]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 35 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 35 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
37it [01:25,  1.21it/s, model 1=1290, model 1+2=1005, eta=46.063/8.716, auroc (pub)=0.907547]38it [01:25,  1.42it/s, model 1=1290, model 1+2=1005, eta=46.063/8.716, auroc (pub)=0.907547]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 36 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
38it [01:25,  1.42it/s, model 1=1342, model 1+2=1005, eta=44.382/8.716, auroc (pub)=0.904549]39it [01:25,  1.81it/s, model 1=1342, model 1+2=1005, eta=44.382/8.716, auroc (pub)=0.904549]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 37 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
39it [01:25,  1.81it/s, model 1=1401, model 1+2=1005, eta=42.609/8.716, auroc (pub)=0.904085]40it [01:25,  2.24it/s, model 1=1401, model 1+2=1005, eta=42.609/8.716, auroc (pub)=0.904085]05_inference_torch_ort.py:646: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_mask = np.ones ((n_users, chunk_size), dtype=np.bool)
05_inference_torch_ort.py:647: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_cat  = np.zeros((n_users, chunk_size, len(cat_names)),  dtype=np.long)
05_inference_torch_ort.py:649: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  x_tags = np.zeros((n_users, chunk_size, 6), dtype=np.long)
/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py:210: UserWarning: Fallback to PyTorch due to exception <class 'onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException'> was triggered. Report this issue with a minimal repro at https://www.github.com/microsoft/onnxruntime. See details below:

RuntimeError: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 235, in get_exception_as_string
    raise exception
  [Previous line repeated 38 more times]
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_inference_manager.py", line 84, in forward
    build_graph = self._export_model(*inputs, **kwargs)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 294, in _export_model
    self._onnx_models.exported_model = self._get_exported_model(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_graph_execution_manager.py", line 361, in _get_exported_model
    raise wrap_exception(ORTModuleONNXModelException,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/onnxruntime/training/ortmodule/_fallback.py", line 226, in wrap_exception
    raise new_exception(raised_exception) from raised_exception
onnxruntime.training.ortmodule._fallback.ORTModuleONNXModelException: There was an error while exporting the PyTorch model to ONNX: Exporting the operator embedding_renorm to ONNX opset version 12 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.

  warnings.warn(
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 2 (pid: 169986) of binary: /home/azureuser/miniconda3/envs/riiid-py38-torch-191/bin/python
Traceback (most recent call last):
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/run.py", line 689, in run
    elastic_launch(
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/azureuser/miniconda3/envs/riiid-py38-torch-191/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 244, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
***************************************
    05_inference_torch_ort.py FAILED   
=======================================
Root Cause:
[0]:
  time: 2022-01-26_20:38:06
  rank: 2 (local_rank: 2)
  exitcode: 1 (pid: 169986)
  error_file: <N/A>
  msg: "Process failed with exitcode 1"
=======================================
Other Failures:
  <NO_OTHER_FAILURES>
***************************************

